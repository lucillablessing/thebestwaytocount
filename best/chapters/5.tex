\documentclass[../best.tex]{subfiles}

\begin{document}

\mychapter[five]{binary fractions glow red, and red is bad}

even though positional notation was originally only invented for natural numbers, extending it to include \emph{negative} powers of the base allows us to notate fractions as well, by introducing a new symbol called the {\it radix point}. in this notation, rational numbers fall into two categories. some have a terminating expansion, if they can be multiplied by some power of the base to yield an integer; the others have an infinite expansion, but eventually fall into a periodic pattern that repeats forever: these are {\it recurring fractions}. it might not be obvious at first, but every rational number in every base is either terminating or recurring -- this follows from Fermat's Little Theorem plus the formula for the sum of a geometric series.\myfootnote{}

as before, decimal provides the most well-known examples. $1/2$ is written as .5, because it's equal to $5/10$, and $1/5$ is written as .2, because it's equal to $2/10$. fractions with denominators containing primes other than 2 or 5 will be recurring in decimal, such as $1/6$, written as .1666..., with infinitely many sixes afterwards -- ``point one rep six'', if you will. traditionally, to notate a recurring fraction, the \emph{entire} recurring segment is marked, but that doesn't make a lot of sense: it's simpler to just mark where it \emph{starts}.

and that's the approach we'll be using for our binary notation. we will be using this symbol for the radix point -- a little below the baseline -- and this symbol for the... ``recurring point''. also, if they both occur in the same position, the radix point is omitted. so $1/2$ is .1, $1/3$ is r01, and $1/6$ is .0r01.\mytranscript{43:40}

there are a few simple patterns that show up in every base $b$: .1 always means $1/b$, r1 always means $1/(b-1)$, and if we denote the base's largest digit by Z, then r0Z always means $1/(b+1)$. for example, in decimal, .1 means $1/10$, r1 means $1/9$, and r09 means $1/11$.

these patterns occur because these fractional expansions are closely related to the divisibility tests we looked at earlier. $1/9$ has a period of 1 because 9 divides $10 - 1$, and $1/11$ has a period of 2 because 11 divides $10^2 - 1$. another connection is to cyclic numbers. if $k$ is cyclic in base $b$, then the period of $1/k$ will attain its maximum in base $b$: \emph{this} is what a cyclic number means. for example, 5 is a cyclic number in both binary and dozenal, and in both of those $1/5$ has its longest possible period, which is 4 digits.\myfootnote{}

in {\it a better way to count}, these links are taken to the extreme, and the two are assumed to be the same thing. as a result, it puts \emph{way} too much emphasis on how different bases write the reciprocals of the positive integers. again, it seems like there's this underlying assumption that the period lengths of these representations can say \emph{everything} about the merit of a base.

once again, to expose why such a logical leap is incorrect, we can follow it to its conclusions. let's look at the expansions of some simple fractions, up to $1/12$, in both binary and seximal. of these, in binary, $1/3$, $1/5$, $1/9$, and $1/11$ are all cyclic, being the longest they could possibly be, and $1/6$, $1/10$, and $1/12$ also share their period lengths. they're all marked in red. meanwhile, in seximal, only $1/11$ is cyclic, and its period is the same length as for binary, while all other fractions in this range are much shorter.\myfootnote{}

judging by this table, seximal is clearly superior to binary. but check this out: let's add base 4 into the mix. suddenly, things are looking fishy. base 4 has \emph{no} ratios that glow red, no matter how far you go, because it has no cyclic numbers. that's because base 4 is just a compression of the information already present in base 2 into pairs. and since all cyclic numbers in binary correspond to even periods,\myfootnote{} their length is halved when represented in base-4 digits, so it'll never reach its maximum. the same is true for all other \emph{square} bases: those are precisely the ones that have finitely many cyclic numbers, possibly none at all.\myfootnote{}

but we already know that doesn't mean base 4 is better than base 2. those two bases convey \emph{exactly} the same information, only base 4 does it slightly worse because it requires grouping bits into pairs. which actually is also visible in this picture: note how $1/7$ is 3 digits in base 2, and also 3 digits in base 4 -- that's because grouping a period of 3 bits into pairs doesn't make the period length any shorter. this problem shows up everywhere in power bases, here it is yet again: enforcing one particular grouping. we know for certain that base 4 is worse than binary, and yet according to this table, it looks not only better than binary, but better than \emph{seximal} -- since seximal has infinitely many cyclic numbers, whereas base 4 has none.

the error is, again, that something like 4 binary digits in the representation of $1/5$ are treated as \emph{inherently} bad just because it's a number of digits corresponding to a cyclic number. but just think about it for a moment: are the 4 binary digits for $1/5$ \emph{really} just as bad as the 4 \emph{dozenal} digits for $1/5$? is r0011 \emph{really} just as bad as r2497? and if base 4 is better than binary, why isn't niftimal better than seximal? both of those are just their respective lower base, but with number lengths rounded up to the next even number.\myfootnote{}

what we \emph{actually} need to be looking at is the number of digits weighted by the logarithm of the base itself -- there's no reason to do that when talking about radix economy and then turn it off for fractions.\myfootnote{} this eliminates the bias that presents base 4 as better, since it accounts for the fact that each base 4 digit is worth two binary digits. the failure to take this factor into consideration is the single biggest error that permeates nearly all discussion of fractions in seximal. it's present in the comparison of various bases on seximal.net.\mytranscript{48:07} it's present in BASE OFF, which will never recommend binary to you if base 4 is also an option.\mytranscript{48:10} and it's present in the Artifexian video, using a metric that depicts binary as the worst power-of-two base -- here's the correct version, if you're curious.\mytranscript{48:15}

if we compare with this metric in mind, all of a sudden the proportions change dramatically. base 4 is now visibly worse than binary -- always either worse or equal -- and \emph{seximal} is better than binary in this range only for $1/5$, $1/6$, and $1/9$.\myfootnote{} note for example that even though $1/7$ in binary contains \emph{three} digits, those three digits together actually cost \emph{less} than the \emph{two} digits required to write $1/7$ in seximal. in fact, any time a cyclic number occurs in any higher base, binary is guaranteed to be more efficient.\myfootnote{}

but of \emph{course} binary's score approaches seximal if we give it such a huge advantage: doesn't it just mean seximal is so good that its scores are still similar despite being three times bigger? well, there's even more to this fraction argument than that. as {\it a better way to count} correctly established, the true deal with fractions isn't that some contain more information than others, but that some are easier to re-derive from scratch than others.

in decimal, if for some reason you forget how to write $1/4$, it's not that difficult to figure out from scratch. since 4 is a factor of 100, all you need to do is divide 100 by 4 and write the result shifted 2 decimal places to the right: .25. on the other hand, if you forget how to write $1/7$, you're basically out of luck. being able to not only figure out that 7 is a factor of 999,999, but then also dividing them in your head and finding that the quotient is 142,857, isn't something that anyone would expect you to be able to do.

in \emph{binary}, on the other hand, you can derive almost any fraction almost instantly. check it out:

\begin{itemize}
	\item $1/2$, $1/4$, and $1/8$ are .1, .01, and .001, respectively.
	\item $3 = 4 - 1$, so $1/3$ is r1 in base 4, and $1/6$ and $1/12$ are just a half and a quarter of that respectively, so they just add more zeros at the start.
	\item $5 = 4 + 1$, so $1/5$ is r0Z in base 4, and $1/10$ is just half of that, so just add a zero at the start.
	\item $7 = 8 - 1$, so $1/7$ is r1 in base 8.
	\item $9 = 8 + 1$, so $1/9$ is r0Z in base 8.
\end{itemize}

that's \emph{all} the ratios in the range we've looked at, except for $1/11$, derived from scratch in a matter of seconds. in particular, binary's first three cyclic numbers -- 3, 5, and 9 -- no longer look that bad anymore: they're all of the form $2^n + 1$, and they have periods of length $2 \times n$, where the left half is all zeros and the right half is all ones. they're not at all pesky like typical cyclic numbers are.

in seximal, many of those are about as easy. however, $1/8$ requires us to divide $6^3$ by $2^3$, which amounts to calculating $3^3$ -- which, if you're new to seximal, isn't brain dead trivial. and $1/10$ involves the product of a prime in the base with a prime outside of the base, and is also somewhat tricky to compute.

this connects very well to a point about terminating expansions. yes, in seximal, any fractions with powers of two \emph{or} three in the denominator will terminate, whereas in binary it has to be just powers of two -- but that might not be such a bad thing. after all, \emph{almost all} fractional expansions in \emph{any} base will be recurring,\myfootnote{} so in the long run a base should face its recurring expansions honorably, rather than trying to flee from them as much as it can. the compatible denominators for seximal might be common among the first few numbers, but if you mark them for a bigger range, you can see how quickly they become extremely rare.\mytranscript{51:37} also, in a base divisible by two prime factors, like seximal, we've seen how the reciprocals of the powers of one prime need some effort to derive, and mixing primes inside and outside the base leads to problems as well. in binary, both of those are avoided -- this is because, again, we can handle any number simply by factoring it into a power of two component and an odd component.\myfootnote{}

there's even more to see, though.\mytranscript{52:07} one comment on {\it a better way to count} talks about how balanced dozenal can allegedly combine the power of dozenal factors with the simplicity of seximal fractions, saying in particular that fifths are two recurring digits and sevenths are three.\myfootnote{} how can that be? after all, balanced dozenal is still just dozenal, so how can it have fractional expansions that are half as long? looking at the website reveals that, as expected, the claim is false -- at least partially. $1/7$ in balanced dozenal indeed has \emph{six} recurring digits, it's just that half of them are the negatives of the other half. still, that might seem astonishing at first... until you notice something else.

take a look at binary again. the first three cyclic numbers are all zeros followed by all ones, but other cyclic numbers also follow a generalized pattern: the left half is the bit negation of the right half. binary does the same halving thing as balanced bases do.\myfootnote{} in fact, not just binary: \emph{every base} does this -- this is known as Midy's theorem.\myfootnote{} but did you ever notice that in decimal $1/7$, the left half is the nines' complement of the right half? did you notice it in dozenal $1/5$? in seximal $1/11$? just because of how noticeable it is in binary specifically, it probably took you all the way until binary to notice it ever existed in the first place.\myfootnote{}

but let's get back to the star of our show: the elusive $1/11$. the number that both seximal and binary shun so much... or \emph{do} they?

remember the ``magic sequence'' thing from divisibility tests? let's bring up the magic sequence for 11 one more time: 1, 2, 4, 8, 5, 10, 9, 7, 3, 6, 1. now, between every pair of numbers, let's mark where the numbers are ascending and where they're descending, and write a 0 at every increase and a 1 at every decrease. and because the magic sequence loops indefinitely, so does our sequence of bits, and... hang on, this \emph{is} $1/11$ in binary!\myfootnote{} just like that, without doing any cumbersome division by huge numbers in our heads, we figured out how to write $1/11$ in binary using the magic sequence for 11.\myfootnote{}

if we \emph{really} wanted to do this in higher bases, we \emph{could}, but we'd run into two issues. the first is one we already know: to generate the magic sequence, we need to multiply numbers by the \emph{base} at each step. but the second issue is a lot bigger. remember how the numbers in magic sequences in higher bases grow so fast that overflow can occur multiple times? well, get this: in higher bases, to determine the digit at a particular position, you have to know \emph{how many times} overflow has occurred from one position to the next. in other words, you have to do not just a straightforward modulo calculation, but straight up \emph{division}, at each step of the magic sequence. once again, a method for which binary is simple enough completely falls apart for higher bases.\myfootnote{}

magic sequences are an extremely powerful tool in binary. they're like a number's DNA sequence: they're trivial to compute, and they unlock all sorts of things that would require far more complex methods in higher bases -- so much that perhaps learning \emph{them} would be the binary equivalent of learning the multiplication table. so while seximal handles the first few primes astonishingly well, with higher primes, it doesn't even give you the option. meanwhile, binary gives \emph{all} the numbers equal treatment. seximal may win a sprint, but binary wins the marathon.

\end{document}